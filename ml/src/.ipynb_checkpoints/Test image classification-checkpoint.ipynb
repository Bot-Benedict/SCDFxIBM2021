{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2901d95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43011826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa3da288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1429f07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I get data_list with\n",
    "fire_data_list = glob.glob('../datasets/fire/fire/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "763d0303",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [np.array(Image.open(v)) for v in fire_data_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e5376c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_width=sum([Image.open(v).width for v in fire_data_list])/len(fire_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd11b085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "494.3685220729367"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ave_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "232e3e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_height=sum([Image.open(v).height for v in fire_data_list])/len(fire_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc1d5aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "425.531669865643"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ave_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23c11088",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_data=[np.array(Image.open(v).resize((495,426))) for v in fire_data_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa3747ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 495, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b58249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_data_list = glob.glob('../datasets/traffic_incident/traffic_incident/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb7b258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_width=sum([Image.open(v).width for v in traffic_data_list])/len(traffic_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1845379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "455.0247422680412"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ave_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ca55f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_height=sum([Image.open(v).height for v in traffic_data_list])/len(traffic_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53553f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "423.75876288659794"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ave_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56a88bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_data=[np.array(Image.open(v).resize((495,426))) for v in traffic_data_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "544df8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_labels=[0]*len(fire_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "071379dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_labels=[1]*len(traffic_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b04bd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data=fire_data+traffic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "787cad62",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_labels=fire_labels+traffic_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6fa48f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_labels=np.array(total_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18f8df2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data=np.array(total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8606bcb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_data)==len(total_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be7e1b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "289abd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab7aae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6725f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(495, 426,3)),\n",
    "    tf.keras.layers.Dense(2100, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "'''\n",
    "model = Sequential([\n",
    "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(495, 426, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "68eecb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3264142f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.2471 - accuracy: 0.9072WARNING:tensorflow:Model was constructed with shape (None, 495, 426, 3) for input Tensor(\"rescaling_input:0\", shape=(None, 495, 426, 3), dtype=float32), but it was called on an input with incompatible shape (None, 426, 495, 3).\n",
      "29/29 [==============================] - 83s 3s/step - loss: 0.2471 - accuracy: 0.9072 - val_loss: 0.7362 - val_accuracy: 0.6436\n",
      "Epoch 2/5\n",
      "29/29 [==============================] - 86s 3s/step - loss: 0.1682 - accuracy: 0.9359 - val_loss: 0.1601 - val_accuracy: 0.9010\n",
      "Epoch 3/5\n",
      "29/29 [==============================] - 80s 3s/step - loss: 0.0908 - accuracy: 0.9757 - val_loss: 0.2221 - val_accuracy: 0.9010\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - 77s 3s/step - loss: 0.0419 - accuracy: 0.9923 - val_loss: 0.4838 - val_accuracy: 0.7723\n",
      "Epoch 5/5\n",
      "29/29 [==============================] - 81s 3s/step - loss: 0.0567 - accuracy: 0.9823 - val_loss: 0.3140 - val_accuracy: 0.8416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1efce7c2ac8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(total_data, total_labels, epochs=5,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c3befd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampletest = glob.glob('../datasets/sampletest/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "77765d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampletest=[np.array(Image.open(v).resize((495,426))) for v in sampletest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6f7d9926",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampletest=np.array(sampletest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5c52d7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(sampletest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d9651d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = tf.nn.softmax(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eda4a277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to Fire with a 100.00 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(['Fire','Traffic'][np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "91937094",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1006, 426, 495, 3)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "00b637c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1006"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "59add292",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-113-109a1f2203b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtotal_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "total_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5c7a56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6889731e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([60, 70, 61], dtype=uint8)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "39de7b09",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-de0e23bfb6d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'tuple'"
     ]
    }
   ],
   "source": [
    "sum(Image.open(f, 'r').size for f in data_list)/len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c206b080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "image_array = array([Image.open(f, 'r').size for f in data_list])\n",
    "print(image_array.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "327bdfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_size(path):\n",
    "    width, height = Image.open(path).size\n",
    "    return width*height\n",
    "\n",
    "largest = max(data_list, key=get_img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3afdae7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../datasets/fire/fire\\\\fire_image0022.jpg'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "largest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54227b61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
